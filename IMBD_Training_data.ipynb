{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\",\n",
    "            header =0,\n",
    "            delimiter = \"\\t\", \n",
    "            quoting=3\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review):\n",
    "    #function to clean a single review\n",
    "    example1 = BeautifulSoup(raw_review).get_text() #Review HTML XML\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", #The patter to search for, Everything except the following.\n",
    "                     \" \", # the pattern to replace it with\n",
    "                     example1 #The text to search for\n",
    "                     )\n",
    "    \n",
    "    words = letters_only.lower().split()\n",
    "    #remove stop words from \"words\"\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w\n",
    "            for w in words\n",
    "            if not w in stops]\n",
    "    return (\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_train_reviews = [review_to_words(w) for w in train[\"review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dist = np.sum(train_data_features, axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([187, 125, 108, ..., 740, 518, 147])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = forest.fit (train_data_features, train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"testData.tsv\",\n",
    "                  header =0,\n",
    "                  delimiter =\"\\t\",\n",
    "                  quoting =3 )\n",
    "\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000  of 25000\n",
      "\n",
      "Review 2000  of 25000\n",
      "\n",
      "Review 3000  of 25000\n",
      "\n",
      "Review 4000  of 25000\n",
      "\n",
      "Review 5000  of 25000\n",
      "\n",
      "Review 6000  of 25000\n",
      "\n",
      "Review 7000  of 25000\n",
      "\n",
      "Review 8000  of 25000\n",
      "\n",
      "Review 9000  of 25000\n",
      "\n",
      "Review 10000  of 25000\n",
      "\n",
      "Review 11000  of 25000\n",
      "\n",
      "Review 12000  of 25000\n",
      "\n",
      "Review 13000  of 25000\n",
      "\n",
      "Review 14000  of 25000\n",
      "\n",
      "Review 15000  of 25000\n",
      "\n",
      "Review 16000  of 25000\n",
      "\n",
      "Review 17000  of 25000\n",
      "\n",
      "Review 18000  of 25000\n",
      "\n",
      "Review 19000  of 25000\n",
      "\n",
      "Review 20000  of 25000\n",
      "\n",
      "Review 21000  of 25000\n",
      "\n",
      "Review 22000  of 25000\n",
      "\n",
      "Review 23000  of 25000\n",
      "\n",
      "Review 24000  of 25000\n",
      "\n",
      "Review 25000  of 25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(0,num_reviews):\n",
    "    if ((i+1) %1000 == 0):\n",
    "        print \"Review %d  of %d\\n\" %(i+1,num_reviews)\n",
    "    clean_review = review_to_words( test[\"review\"][i])\n",
    "    clean_test_reviews.append(clean_review)\n",
    "    \n",
    "    \n",
    "test_data_features = vectorizer.transform(clean_test_reviews).toarray()\n",
    "\n",
    "result = forest.predict(test_data_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    output = pd.DataFrame (data={\"id\":test[\"id\"],\"sentiment\":result})\n",
    "\n",
    "    output.to_csv(\"Bag_of_words_model.csv\",index=False, quoting=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
